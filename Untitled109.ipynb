{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled109.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "so-mP56hoaKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "4c42bf26-63ed-4217-8971-024b5d162e8c"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 250)               4000250   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 4,160,501\n",
            "Trainable params: 4,160,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            " - 30s - loss: 0.4409 - acc: 0.7740 - val_loss: 0.2879 - val_acc: 0.8784\n",
            "Epoch 2/10\n",
            " - 34s - loss: 0.1587 - acc: 0.9423 - val_loss: 0.3235 - val_acc: 0.8713\n",
            "Epoch 3/10\n",
            " - 34s - loss: 0.0448 - acc: 0.9883 - val_loss: 0.4399 - val_acc: 0.8600\n",
            "Epoch 4/10\n",
            " - 36s - loss: 0.0089 - acc: 0.9987 - val_loss: 0.5408 - val_acc: 0.8590\n",
            "Epoch 5/10\n",
            " - 35s - loss: 0.0019 - acc: 0.9999 - val_loss: 0.5770 - val_acc: 0.8647\n",
            "Epoch 6/10\n",
            " - 35s - loss: 5.9837e-04 - acc: 1.0000 - val_loss: 0.6093 - val_acc: 0.8652\n",
            "Epoch 7/10\n",
            " - 35s - loss: 3.5281e-04 - acc: 1.0000 - val_loss: 0.6318 - val_acc: 0.8658\n",
            "Epoch 8/10\n",
            " - 35s - loss: 2.4090e-04 - acc: 1.0000 - val_loss: 0.6515 - val_acc: 0.8660\n",
            "Epoch 9/10\n",
            " - 35s - loss: 1.7569e-04 - acc: 1.0000 - val_loss: 0.6691 - val_acc: 0.8663\n",
            "Epoch 10/10\n",
            " - 34s - loss: 1.3256e-04 - acc: 1.0000 - val_loss: 0.6837 - val_acc: 0.8667\n",
            "Accuracy: 86.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ffpZhcoeaU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "e4f4cbd1-bef4-4e69-aaf5-79479934a463"
      },
      "source": [
        "from lib import plotting "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-820ea02647ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prcRRnK8o95s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}